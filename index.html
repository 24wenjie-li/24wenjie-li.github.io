<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Wenjie Li</title>

    <meta name="author" content="Wenjie Li">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Wenjie Li
                </p>
                <p style="text-align: justify;"> Wenjie Li (ÊùéÊñáÊù∞) is a first year Ph.D. candidate at Department of Artificial Intelligence, Beijing University of Posts and Telecommunications (BUPT), advised by Prof. <a href="https://zhanyuma.cn/" target="_blank">Zhan-Yu Ma</a> and co-advised by Prof. <a href="https://gh-home.github.io/" target="_blank">Heng Guo</a>. My research interests include deep learning and computer vision, particularly focusing on face/image restoration.
                </p>
                <p style="text-align: justify;">
                  Prior to BUPT, I received master's degree at Nanjing University of Posts and Telecommunications (NUPT) in 2023, under the supervision of Prof. <a href="https://guangweigao.github.io/" target="_blank">Guangwei Gao</a>. And I worked as a research intern at <a href="https://www.megvii.com/">Megvii Technology</a>.
                </p>
                <p style="text-align:center">
                   <a href="mailto:lewj2408@gmail.com">Email</a> &nbsp &nbsp  &nbsp
                   <a href="https://scholar.google.com.hk/citations?user=8_-tznoAAAAJ&hl=zh-CN"><i class="fa fa-graduation-cap fa-fw" style="font-size:100%;width:4.2ch;margin-top:1px;"></i>Scholar</a> &nbsp &nbsp  &nbsp
                   <a href="https://github.com/24wenjie-li"><i class="fa fa-github" style="font-size:120%;width:4ch;margin-top:1px;"></i>Github</a> &nbsp &nbsp  &nbsp
                   <a href="publication.html"><i class="fa fa-file-o fa-fw" style="font-size:100%;width:4ch;margin-top:1px;"></i>Publication</a> &nbsp &nbsp  &nbsp 
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="img/lwj23_white.jpg"><img style="width:90%;max-width:90%" alt="profile photo" src="img/lwj23_white.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>




        






        <!-- News -->
        <div id="news">
          <h2 class="noselect">News</h2>
          <div class="news-container">
              <ul class="news-list noselect">
                  <li class="news-item">2025/07 -- Code release for <a href="https://github.com/Adam-duan/DiT4SR">DiT4SR</a> on github!</li>
                  <li class="news-item">2025/06 -- We present <a href="projects/ultraled">UltraLED</a>, captured one moving UHDR scenes with only one shot! And Excited to announce <a href="https://adam-duan.github.io/projects/dit4sr/">DiT4SR</a> got accepted by <a href="https://iccv.thecvf.com/Conferences/2025">ICCV</a> 2025.</li>
                  <li class="news-item">2025/06 -- Code release on <a href="https://github.com/Adam-duan/DiffRetouch">github</a> for <a href="https://adam-duan.github.io/projects/retouch/">DiffRetouch</a>! And we update a <a href="assets/paper_translated/24NIPS_LE3D.pdf">‰∏≠ÊñáÊñáÁ´†</a> for LE3D!</li>
                  <li class="news-item">2025/04 -- Excited to announce <span class="bold">Towards RAW Object Detection in Diverse Conditions</span> has been selected as a Highlight paper by <a href="https://cvpr.thecvf.com/Conferences/2025">CVPR</a> 2025!</li>
                  <li class="news-item">2025/02 -- Two papers got accepted by <a href="https://cvpr.thecvf.com/Conferences/2025">CVPR</a> 2025! <span class="particle-text">Maybe one is gonna be hosted in <a href="https://www.adobe.com/products/premiere.html">Premiere Pro</a> &#x1F92B;</span></li>
                  <li class="news-item">2025/02 -- We released the <a href="assets/paper_translated/23ICCV_LED.pdf">Chinese version</a> of Lighting Every Darkness in Two Pairs: A Calibration-Free Pipeline for RAW Denoising; and <a href="/projects/le3d/index.html">LE3D</a>'s explanation on <a href="https://zhuanlan.zhihu.com/p/703582016">Áü•‰πé</a>.</li>
                  <li class="news-item">2025/01 -- We released the <a href="assets/paper_translated/23CVPR_DNF.pdf">Chinese version</a> of DNF: Decouple and Feedback Network for Seeing in the Dark.</li>
                  <li class="news-item">2025/01 -- Code release on <a href="https://github.com/Srameo/LE3D">github</a> for <a href="/projects/le3d/">LE3D</a>!</li>
                  <li class="news-item">2025/01 -- We release a <a href="/projects/le3d/index.html">web viewer</a> for <a href="/projects/le3d/index.html">LE3D</a>!</li>
                  <li class="news-item">2024/12 -- <a href="https://adam-duan.github.io/projects/retouch/">DiffRetouch</a> has been accepted by AAAI 2025!</li>
                  <li class="news-item">2024/10 -- <a href="/projects/le3d/">LE3D</a> has been accepted by NeurIPS 2024! We are working on the release of the code. Please stay tuned! Hope to see you guys at Vancouver, Canada!</li>
                  <li class="news-item">2024/06 -- We present <a href="/projects/le3d/">LE3D</a>, enabling real-time rendering for HDR view synthesis!</li>
                  <li class="news-item">2024/01 -- The <a href="https://codalab.lisn.upsaclay.fr/competitions/17017">Few-shot RAW Image Denoising Track</a> in MIPI 2024 has started!</li>
                  <li class="news-item">2023/12 -- A honor to co-organize the <a href="https://mipi-challenge.org/MIPI2024/">MIPI workshop</a> @ CVPR2024 with NTU S-Lab!</li>
                  <li class="news-item">2023/12 -- We have released a <a href="/projects/led-extension/">extension version</a> of our <a href="/projects/led-iccv23/">LED</a>. Code is also released on <a href="https://github.com/Srameo/LED">Github</a>!</li>
                  <li class="news-item">2023/07 -- The official code of <span class="italic">Lighting Every Darkness in Two Pairs: A Calibration-Free Pipeline for RAW Denoising</span> has been released on <a href="https://github.com/Srameo/LED">Github</a>!</li>
                  <li class="news-item">2023/07 -- One paper, including <a href="/projects/led-iccv23/">LED</a>, got accepted by ICCV 2023.</li>
                  <li class="news-item">2023/05 -- The official code of <span class="italic">DNF: Decouple and Feedback Network for Seeing in The Dark</span> has been released on <a href="https://github.com/Srameo/DNF">Github</a>!</li>
                  <li class="news-item">2023/03 -- Excited to announce one paper accepted by CVPR 2023 was selected as <span class="bold">Highlight, 10% of accepted papers, 2.5% of submissions</span>!</li>
                  <li class="news-item">2023/03 -- One paper got accepted by CVPR 2023.</li>
                  <li class="news-item">2023/01 -- Our paper was awarded <span class="bold">oral presentation</span> qualification by AAAI.</li>
                  <li class="news-item">2022/11 -- One paper got accepted by AAAI 2023.</li>
                  <li class="news-item">2022/04 -- I have won the third place in RAW Image Blind De-noising as the team leader in Megcup 2022!</li>
                  <li class="news-item">2022/04 -- Our team have won the third place in Night Photography Rendering Challenge, CVPRW 2022!</li>
                  <li class="news-item">2022/03 -- One paper got accepted by ICPR 2022 and selected as <span class="bold">oral presentation</span>.</li>
              </ul>
          </div>
      </div>


        
 
        <div class="section" id="news">
          <h2>Recent News</h2>
            <div class="paper">
            <p>2024/07 - One paper was accepted by TMM 2024.</p>
            <p>2024/07 - One paper was accepted by ACMMM 2024.</p>
            <p>2024/04 - One paper was accepted by ACM CSUR 2024.</p>
            <p>2023/05 - One paper was accepted by TMM 2023.</p>
<!--             <p>2022/04 - One paper was accepted by IJCAI 2022. (<font color="orange">Image super-reslution</font>)</p>
            <p>2021/12 - One paper was accepted by AAAI 2022. (<font color="orange">Image super-reslution</font>)</p>
            <p class="hidden_news" style="display:none">2020/10 - One paper was accepted by TCSVT (video deblurring).</p>
            <p class="hidden_news" style="display:none">2020/05 - One paper was accepted by CVIU (image dehazing).</p>  
            <p id="ShowLink_news"><a href="#" onclick="var elements = document.getElementsByClassName('hidden_news');for(var i=0; i&lt;elements.length; i++) {elements[i].style.display='block';}document.getElementById('ShowLink_news').style.display='none';document.getElementById('HideLink_news').style.display='block';return false;" title="Show more News"><font size="2">Show more</font></a></p>
            <p id="HideLink_news" style="display:none"><a href="#" onclick="var elements = document.getElementsByClassName('hidden_news');for(var i=0; i&lt;elements.length; i++) {elements[i].style.display='none';}document.getElementById('HideLink_news').style.display='none';document.getElementById('ShowLink_news').style.display='block';return false;" title="Show less News"><font size="2">Show less</font></a></p> -->
          
            </div>
          </div>

         <br><br>



        




      


<!--           <div class="section">
            <h2>Preprints Papers</h2>
              <div class="research">
                <p>+ Equal contribution, * Corresponding author.</p>

                <papertitle> Survey on Deep Face Restoration: From Non-blind to Blind and Beyond, </papertitle>
                <br> <strong>Wenjie Li</strong>, Mei Wang, Kai Zhang, Juncheng Li, Xiaoming Li, Yuhang Zhang, Guangwei Gao*, Weihong Deng* and Chia-Wen Lin, <br> 
                <em> arXiv:2309.15490, 2023. (<strong><font color="red">Under Review</font></strong>) </em>
                <br>
                [<a href="https://arxiv.org/pdf/2309.15490.pdf">PDF</a>]
                [<a href="https://github.com/24wenjie-li/Awesome-Face-Restoration">Github</a>]
                <p></p>

  

    
              </div>
          </div>
  
  
        <br><br> -->




        




        
         <div class="section">
          <h2>Publish Papers</h2>
            <div class="research">
              <p>+ Equal contribution, * Corresponding author.</p>

              <papertitle> Efficient Image Super-Resolution with Feature Interaction Weighted Hybrid Network, </papertitle>
              <br> <strong>Wenjie Li</strong>, Juncheng Li, Guangwei Gao*, Weihong Deng, Jian Yang, Guojun Qi, Chia-Wen Lin, <br> 
              <em> IEEE Transactions on Multimedia (TMM), 2024. (<strong><font color="red">Top multimedia journal, JCR-Q1, IF=8.4</font></strong>) </em>
              <br>
              [<a href="https://arxiv.org/abs/2212.14181">PDF</a>]
              [<a href="https://github.com/24wenjie-li/FIWHN">Github</a>]
              <p></p>

              <papertitle> Efficient Face Super-Resolution via Wavelet-based Feature Enhancement Network, </papertitle>
              <br> <strong>Wenjie Li</strong>, Heng Guo*, Xuannan Liu, Kongming Liang, Jiani Hu, Zhanyu Ma, Jun Guo, <br> 
              <em> ACM Multimedia (ACM MM), 2024. (<strong><font color="red">Top multimedia conference, Poster</font></strong>) </em>
              <br>
              [<a href="https://arxiv.org/pdf/2407.19768">PDF</a>]
              [<a href="https://github.com/PRIS-CV/WFEN">Github</a>]
              <p></p>

              <papertitle> A Systematic Survey of Deep Learning-based Single-Image Super-Resolution, </papertitle>
              <br> Juncheng Li, Zehua Pei, <strong>Wenjie Li</strong>, Guangwei Gao, Longguang Wang, Yingqian Wang, Tieyong Zeng*, <br> 
              <em> ACM Computing Surveys (ACM CSUR), 2024. (<strong><font color="red">Top survey journal, JCR-Q1, IF=23.8</font></strong>) </em>
              <br>
              [<a href="https://dl.acm.org/doi/10.1145/3659100">PDF</a>]
              [<a href="https://github.com/CV-JunchengLi/SISR-Survey">Github</a>]
              <p></p>

              
              <papertitle> Cross-receptive Focused Inference Network for Lightweight Image Super-Resolution, </papertitle>
              <br> <strong>Wenjie Li</strong>, Juncheng Li, Guangwei Gao*, Weihong Deng, Jiantao Zhou, Jian Yang, Guojun Qi, <br> 
              <em> IEEE Transactions on Multimedia (TMM), 2023. (<strong><font color="red">Top multimedia journal, JCR-Q1, IF=8.4</font></strong>) (<strong><font color="blue">ESI Highly Cited Paper</font></strong>)</em>
              <br>
              [<a href="https://ieeexplore.ieee.org/document/10114600/authors#authors">PDF</a>]
              [<a href="https://github.com/24wenjie-li/CFIN">Github</a>]
              <p></p>

              
              <papertitle> Lightweight Bimodal Network for Single-Image Super-Resolution via Symmetric CNN and Recursive Transformer, </papertitle>
              <br> Guangwei Gao+*, Zhengxue Wang+, Juncheng Li, <strong>Wenjie Li</strong>, Yi Yu, Tieyong Zeng, <br> 
              <em> International Joint Conference on Artificial Intelligence (IJCAI), 2022. (<strong><font color="red">Top artificial intelligence conference, Short Oral</font></strong>)</em>
              <br>
              [<a href="https://www.ijcai.org/proceedings/2022/128">PDF</a>]
              [<a href="https://github.com/wzx0826/LBNet#lbnet-pytorch-lightweight-bimodal-network-for-single-image-super-resolution-via-symmetric-cnn-and-recursive-transformer">Github</a>]
              <p></p>

              
              <papertitle> Feature Distillation Interaction Weighting Network for Lightweight Image Super-resolution, </papertitle>
              <br>Guangwei Gao+*, <strong>Wenjie Li+</font></strong>, Juncheng Li, Fei Wu, Huimin Lu, Yi Yu, <br>
              <em> AAAI Conference on Artificial Intelligence (AAAI), 2022. (<strong><font color="red">Top artificial intelligence conference, Poster</font></strong>)</em>
              <br>
              [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/19946">PDF</a>]
              [<a href="https://github.com/24wenjie-li/FDIWN">Github</a>]
              <p></p>
              
  
            </div>
        </div>


      <br><br>






        

      <div class="section" id="Professional Activities">
        <h2>Experience</h2>
          <div class="Experience">
          <span><strong>2023/09 - Now</strong>, I am a Ph.D student at <a href="https://www.bupt.edu.cn/">BUPT</a>, under the supervision of Prof. <a href="https://zhanyuma.cn/" target="_blank">Zhan-Yu Ma</a> and co-advised by Prof. <a href="https://gh-home.github.io/" target="_blank">Heng Guo</a>.</span>
            <br/><br/>
          <span><strong>2020/09-2023/06</strong>, I was a masters student at <a href="https://www.njupt.edu.cn/">NUPT</a>, supervised by Prof. <a href="https://guangweigao.github.io/" target="_blank">Guang-Wei Gao</a>.</span>
            <br/><br/>
          <span><strong>2022/05-2022/10</strong>, I interned at <a href="https://www.megvii.com/">Megvii Technology</a>, the research topic is 3D human body key point detection.</span>
<!--             <br/><br/> -->
<!--           <span><strong>2016/09-2020/06</strong>, I was an undergraduate student at <a href="https://www.ahpu.edu.cn/">School of Electrical Engineering, AHPU</a>.</span> -->
          </div>
        </div>

       <br><br>
        





        
      <br><br>

      <div class="section" id="Professional Activities">
        <h2>Professional Activities</h2>
          <div class="Professional Activities">
          <p>Conference Reviewer: ACMMM, PRCV, etc.</p> 
<!--           <p>Journal Reviewer: TCSVT, TII, TMM, etc.</p> -->
          </div>
        </div>

       <br><br>




        
        

        <div style="clear:both;">
          
          <p align="center"><font size="2"><a href="http://bjornstenger.github.io/">I like this website</a>  &nbsp &nbsp &nbsp &nbsp &nbsp   <a href="https://jonbarron.info/">Design credit</a></font></p><br />
        </div>


      </td>
    </tr>
  </table>
</body>

</html>
